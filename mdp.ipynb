{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a09875",
   "metadata": {},
   "source": [
    "Recycling robot - Find optimal policy and optimal value functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc3c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['high', 'low']\n",
    "actions = ['search', 'wait', 'recharge']\n",
    "alpha = 0.6 # search; high -> high\n",
    "beta = 0.3 # search; low -> low\n",
    "\n",
    "search_reward = 2\n",
    "search_depletion_reward = -3\n",
    "wait_reward = 1\n",
    "gamma = 0.8 # discount factor\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f34a9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(state):\n",
    "    if state == 'high':\n",
    "        return [\"search\", \"wait\"]\n",
    "    else:\n",
    "        return [\"search\", \"wait\", \"recharge\"]\n",
    "\n",
    "# Transition function: returns a list of (probability, next_state, reward) tuples\n",
    "def transitions(state, action):\n",
    "    if state == 'high':\n",
    "        if action == \"search\":\n",
    "            return [\n",
    "                (alpha, 'high', search_reward),\n",
    "                (1 - alpha, 'low', search_reward),\n",
    "            ]\n",
    "        elif action == \"wait\":\n",
    "            return [(1.0, 'high', wait_reward)]\n",
    "\n",
    "    elif state ==  'low':\n",
    "        if action == \"search\":\n",
    "            return [\n",
    "                (beta, 'low', search_reward),\n",
    "                (1 - beta, 'high', search_depletion_reward),\n",
    "            ]\n",
    "        elif action == \"wait\":\n",
    "            return [(1.0, 'low', wait_reward)]\n",
    "        elif action == \"recharge\":\n",
    "            return [(1.0, 'high', 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b988ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "V = np.zeros(2)\n",
    "theta = 1e-6\n",
    "\n",
    "while True:\n",
    "    delta = 0\n",
    "    Q = {}\n",
    "    for idx, s in enumerate(states):\n",
    "        v = V[idx]\n",
    "        Q[s] = {}\n",
    "\n",
    "        for a in actions(s):\n",
    "            q = 0\n",
    "            for p, s_next, r in transitions(s, a):\n",
    "                q += p * (r + gamma * V[states.index(s_next)])\n",
    "            Q[s][a] = q\n",
    "\n",
    "        V[idx] = max(Q[s].values())\n",
    "        delta = max(delta, abs(v - V[idx]))\n",
    "\n",
    "    if delta < theta:\n",
    "        break\n",
    "\n",
    "Q = {}\n",
    "\n",
    "for idx, s in enumerate(states):\n",
    "    Q[s] = {}\n",
    "    for a in actions(s):\n",
    "        q = 0\n",
    "        for p, s_next, r in transitions(s, a):\n",
    "            q += p * (r + gamma * V[states.index(s_next)])\n",
    "        Q[s][a] = q\n",
    "        \n",
    "# Extract optimal policy\n",
    "policy = {}\n",
    "for s in states:\n",
    "    action_values = {}\n",
    "    for a in actions(s):\n",
    "        q = 0\n",
    "        for p, s_next, r in transitions(s, a):\n",
    "            q += p * (r + gamma * V[states.index(s_next)])\n",
    "        action_values[a] = q\n",
    "\n",
    "    policy[s] = max(action_values, key=action_values.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd53cc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Value Function:\n",
      "V*(high) = 7.5758\n",
      "V*(low) = 6.0606\n",
      "\n",
      "Optimal Q-values:\n",
      "\n",
      "State: high\n",
      "  Q*(high, search) = 7.5758\n",
      "  Q*(high, wait) = 7.0606\n",
      "\n",
      "State: low\n",
      "  Q*(low, search) = 4.1970\n",
      "  Q*(low, wait) = 5.8485\n",
      "  Q*(low, recharge) = 6.0606\n",
      "\n",
      "Optimal Policy:\n",
      "  high -> search\n",
      "  low -> recharge\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Value Function:\")\n",
    "for idx, s in enumerate(states):\n",
    "    print(f\"V*({states[idx]}) = {V[idx]:.4f}\")\n",
    "\n",
    "print(\"\\nOptimal Q-values:\")\n",
    "for state, action_vals in Q.items():\n",
    "    print(f\"\\nState: {state}\")\n",
    "    for action, value in action_vals.items():\n",
    "        print(f\"  Q*({state}, {action}) = {value:.4f}\")\n",
    "\n",
    "# Extract optimal policy\n",
    "print(\"\\nOptimal Policy:\")\n",
    "for state, action_vals in Q.items():\n",
    "    best_action = max(action_vals, key=action_vals.get)\n",
    "    print(f\"  {state} -> {best_action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e66f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
